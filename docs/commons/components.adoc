## Components


### Analysis Components

Smarti uses Redlink NLP for the analysis of Conversations. In addition it provides several specific analysis components that are implemented as extensions to Redlink NLP.

This documentation focus is on those extensions

#### Interesting Terms

Interesting Terms is a kind of Keyword Extraction that uses `tf–idf` over a document corpus to detect the most relevant terms within a conversation. Implementation wise Solr is used to manage the text corpus and Solr MLT requests are used to retrieve relevant terms.

It consists of two analysis components:

1. **Interesting Term Extractor** that marks interesting terms in the conversation. As the text in Conversations is typically to short to calculate the importance based on the content external information like the `tf–idf` value of words are used to calculate the importance of words.
2. **Interesting Phrase Collector** that collects interesting terms marked form possible multiple Interesting Term Extractor and creates Tokens for them. This component can optionally use phrases as annotated by phrase extraction and/or dependency parsing to mark whole phrases that contain words marked as interesting terms.

Tokens created by this component have the type `Keyword` and the Hint `interestingTerm`

For more information on the configuration of Interesting Term Extractors see the according <<smartiConf.adoc#interesting-term,section>> in the Smarti Configuration

#### Token Filter

Analysis Component that applies all registered Token Filters. If a single filter wants to filter a Token the token is removed from the conversation.

##### Stopword Token Filter

This Analysis component allows to filter extracted Tokens based on their value. Filtering is done based on stopword lists. One list is used for all languages where additional language specific lists can also be configured.

See the <<smartiConf.adoc#token-filter-stopword, Stoword Token Filter configuration>> section of the Smarti Configuration for more information.

#### Token Processor

Analysis Component that allows to process extracted Tokens by defined Rules

##### Regex Token Processing Ruleset

Tokens in the original texts are replaced with `<{Token.Type}>`. This allows to wirte regex patters against the type of the token instead of the actual value.

Typically those rules are used to add ``Hint``s to token extracted from a conversation. The following example showns Regex pattern that assigns the `from` and `to` hints to `Place` type tokens extracted from a text

    public MyGermanTokenMatcher(){
        super("de", EnumSet.of(MessageTopic.Reiseplanung),
                EnumSet.of(Type.Date, Type.Place));
        addRule(String.format("vo(?:n|m) (<%s>)", Type.Place), Hint.from);
        addRule(String.format("nach (<%s>)", Type.Place), Hint.to);
    }

_NOTE:_ Currently it is not possible to configure Rules. To add Rulesets code needs to be written.

#### Negated Token Marker

Adds the hint `negated` to extracted Tokens if mention of the Token is negated (e.g. "no Pizzaia", "nicht über München")

#### POS Collector

Allows to create Tokens for Words with specific Part-of-Speech (POS) tags. By default this component is configured to create Tokens with the type `Attribute` for words that are classified as adjectives.

This analysis components also supports a stopword list with words for those no tokens are created.

#### Adjective Location Processor

In German Location mentions often include words that are classified as Adjectives. A typical example would be a reference to the Munich Main Station as `Münchner Hauptbahnhof`. While Named Entity Recognition (NER) typically marks the noun `Hauptbahnhof` as place if often fails to also mark the adjective `Müncher`.

This processor looks for cases like this and changes the Named Entity to also include the adjective.

### Url Extractor

Uses a Regex pattern to find URLs mentioned in conversations and makrs them as Named Entities with tag `url` and type `misc`. Those Named Entities are later converted to Tokens by the Named Entity Collector.

#### Named Entity Collector

This Analysis Component collects low level Named Entity Annotations and adds `Token` for them to the Conversation. The `type` and `tag` of the Named Entity Annotations are mapped to `Token.Type` and `Hints`.


### Templates

Templates are higher level models over extracted `Token`. Templates defines Slots. Those Slots do have specific Roles and may have [0..*] extracted tokens assigned.

#### LATCH Template

LATCH is a model for Information Retrieval. The acronym stands for the different search dimensions that are represented as Roles in this template:

* **L**ocation: Spatial (Geo) based search. In Smarti Tokens with the `Place` type are assigned this role
* **A**lphabet: Refers to the full text component of searches. In Smarti the "surface form" of extracted Keywords and Tokens that do not fall into one of the other dimensions are used.
* **T**time: Refers to the temporal location of the search. In Samrti Tokens with the Time type are assigned this role.
* **C**ategory: Categorizations are also an important search dimension. In Samrti Tokens with the Category type are assigned this role
* **H**ierarchy: Refers to hirarchical searchis like Rating Systems ([1..5] Stars, [0..10] Points ...) but could also be used for price ranges and similar things. Currently this dimension is not used by Smarti.

All roles in this template are optional. The only requirement is that at least a single `Token` is assigned to any of the defined roles.

### Query Builder

#### Solr Search Query Builder

The Solr Search Query Builder uses the <<LATCH Template>> to build a Solr Query based on the configured Solr Endpoint Configuration.

Solr Endpoint Configurations are Client specific and are set by using the <<clientConfig.adoc#,Client Configuration>> and or the <<client-configuration-ui.adoc#, Client Configuration UI>>.

The following listing shows the JSON if such an configuration

    {
        "_class": "io.redlink.smarti.query.solr.SolrEndpointConfiguration",
        "name": null,
        "displayName": "Solr Search Test",
        "type": "solrsearch",
        "enabled": true,
        "unbound": false,
        "solrEndpoint": "http://my.solr.org/test/me",
        "search": {
            "title": {
                "enabled": true,
                "field": "title@de"
            },
            "fullText": {
                "enabled": true,
                "field": "text@de"
            },
            "spatial": {
                "enabled": true,
                "locationNameField": "location",
                "latLonPointSpatialField": null,
                "rptField": null,
                "bboxField": null
            },
            "temporal": {
                "enabled": false,
                "timeRangeField": null,
                "startTimeField": null,
                "endTimeField": null
            },
            "related": {
                "enabled": false,
                "fields": []
            }
        },
        "defaults": {
            "rows": 8,
            "fields": "*,score"
        },
        "result": {
            "numOfRows": 10,
            "mappings": {
                "title": "title",
                "description": "description",
                "type": "type",
                "doctype": "doctype",
                "thumb": "thumb",
                "link": "link",
                "date": "date",
                "source": "source"
            }
        }
    }

where:

* `_class`: This property needs to refer the Java implementation of the configuration class. The value MUST BE `io.redlink.smarti.query.solr.SolrEndpointConfiguration`
*  `name` and `displayName`: Eigher or both of those are required. `name` must be a slug name (`a-z0-9_`). If only one of the two is present the other one is set accordingly. The name MUST BE unique within all solr endpoint configurations for a Client.
*  `type`: refers to the Query Builder Component. The value MUST BE `solrsearch`
*  `enabled`: allows to disable a configuration without deleting it
*  `unbound`: set by the server (read-only). If `true` the Solr Search Query Builder is not available in Smarti
*  `solrEndpoint`: The URL if the Solr Endpoint (the Solr response handler to be used for search requests)
*  `search`: Configuration on how to build Solr Queries based on Information from the LATCH Template
** `title`: Configuration for the title search. The value of Tokens with the Roles **A**lphabet or **L**ocation will be used. The title search terms will get an increased boost.
*** `enabled`: allows to enable/disable title search.
*** `field`: the title field in the Solr index
** `fullText`: full text search. The value of Tokens with the **A**lphabet roles will be used to create search terms
*** `enabled`: allows to enable/disable full text search.
*** `field`: the full text search field in the Solr index. If `null` or empty the default field (or `df` if present) will be used
** `spatial`: **L**ocation role tokens will be used for spatial search terms.
*** `enabled`: allows to enable/disable spatial search.
*** `locationNameField`: The values of spatial tokens will be used to search in this field. If `null` or empty the default field (or `df` if present) will be used.
*** `latLonPointSpatialField`: Lat/long information of Tokens will be used to create query terms for this field. Spatial Tokens without those information will be ignored.
*** `rptField`: Lat/long information of Tokens will be used to create query terms for this field. Spatial Tokens without those information will be ignored.
*** `bboxField`: Lat/long information of Tokens will be used to create query terms for this field. Spatial Tokens without those information will be ignored.
** temporal: Tokens with the role **T**ime will be considered for temporal searches.
*** `enabled`: allows to enable/disable temporal search.
*** `timeRangeField`: Supports temporal queries on a Solr field using the `DateRangeField` field type
*** `startTimeField`: Supports temporal queries on a Solr field using the date field type
*** `endTimeField`: Optional time range support for Solr schemas that use a start/end date field for storing ranges
** `related`: Allows to generate Solr MLT queries to suggest similar documents. This will use the content of the Conversation to search for similar content. Typically this should be only enabled if all other options are disabled.
*** `enabled`: allows to enable/disable Solr MLT queries.
*** `fields`: Array with the fields used for Solr MLT
* `defaults`: A map with solr parameters that are sent with every request (examples `"fq" : "source:(news archive)"` or `"df": "text_de"`, `"fields": "*,score"`, `"rows": 10`, ...)
* `result`: Defines how results are processed
** `numOfRows`: defines the nuber of results in the UI
** `mappings`: Defines how Solr document fields in the results are mapped to fields known by the UI presenting results
*** `title`: the title as shown in the UI
*** `description`: the description as shown in the UI
*** `type`: the type of the result
*** `doctype`: the document type of the result (e.g. `text/html`)
*** `thumb`: the thumbnail used in the UI
*** `link`: the link to the result
*** `date`: the date for the result (e.g. the modification date)
*** `source`: the source of the result
