## logging config file
logging.config = ./logback.xml

## server port
server.port = 8080

## mongo-db
#spring.data.mongodb.uri=mongodb://localhost/smarti
spring.data.mongodb.database = smarti
#spring.data.mongodb.host = localhost
#spring.data.mongodb.port = 27017
#spring.data.mongodb.password =
#spring.data.mongodb.username =

## database-migration-scripts
smarti.migration.mongo.script-home = /usr/share/${binaryName}/scripts

##tomcat AJP-Config
#tomcat.ajp.enabled=false
#tomcat.ajp.protocol=AJP/1.3
#tomcat.ajp.port=9090
#tomcat.ajp.allow-trace=false
#tomcat.ajp.secure=false
#tomcat.ajp.scheme=http

## mail configuration
#spring.mail.host=
#spring.mail.port=
#spring.mail.protocol=smtp
#spring.mail.username=
#spring.mail.password=

##SolrLib Configuration

##for embedded it is recommended to set the solrlib.home to an ABSOLUTE path
##to avoid initialization and indexing of Solr Cores on every startup
#solrlib.home=/absolute/path/to/solr/home

## This will trigger using solrlib-standalone if available on the classpath
##      base-url for all solr requests
#solrlib.base-url = http://localhost:8983/solr
    
## This will trigger using solrlib-cloud if available on the classpath
##       ZooKeeper connection string
#solrlib.zk-connection = zookeeper1:8121,zookeeper2:8121
    
## Only used by standalone and cloud
##      prefix for the remote collection names, 
##      to avoid name-clashes on shared servers. 
#solrlib.collection-prefix = 
    
## Only relevant in cloud-mode
#solrlib.max-shards-per-node = 1
        
## Only used by standalone and cloud
##      option to disable automatic configuration update/deployment
##      to remote servers. You might not have the karma to do so.
#solrlib.deploy-cores = true
    
## Only used by embedded
##      option to delete the solrlib-home upon shutdown
#solrlib.delete-on-shutdown = false


##UI Cache

## The maximum age of elements in the cache in seconds 
## (default: `864000` - 10 days). If `< 0` no cache will be used.
#ui.cache.maxAge = 864000

## The maximum age of a cached `index.hmtl` (default: `3600` - 1 hour). 
## If `< 0` no cache will be used.
#ui.cache.indexMaxAge = 3600


##CORS

#cors.enabled = true


##Property Injection

## Allows to inject backend properties in the Frontend
#resource.transform.inject.text = constants*.js


##Default Wbservice Error Handler

## Note that even if disabled stacktraces for `5**` responses will be logged.
#webservice.errorhandler.writetrace = false


##Jsonp callback

## The name of the callback
#jsonp.callback = callback


## Http Callback configuration
#http.retryCount=3
#http.callback.proxy.hostname=127.0.0.1
#http.callback.proxy.port=8181
#http.callback.proxy.scheme=http


##Speak Service

## The Speak Service managed resource bundles for bot generated replay messages
## in conversations.
#message.locale = de_DE
#message.source =


##Conversation Indexing


## Rebuild on Startup

#enable/disable full rebuild of indexes on startup (default: true)
#smarti.index.rebuildOnStartup = true


## Conversation are indexed in Solr managed by SolrLib

## Defines the maximum time span until after published conversations are
## available in the index. Values are in milliseconds. For values `< 0`
## the default `10` seconds will be used. For values `>= 0 < 1000` the minimum
## value of `1000ms` will be used.
#smarti.index.conversation.commitWithin = -1

## Multiple messages of the same users are merged to a single message if they
## where sent within the configured time period. Values are in Seconds. The
## default is `30` seconds.
#smarti.index.conversation.message.merge-timeout = 30


## Processing

## The number of threads used for processing conversation
#smarti.processing.numThreads = 2


##Analysis configuration

##Conversation Language configuration
##Set {lang} as language for the conversations
#smarti.analysis.language=de
##The number of messages analyzed for a conversation (-1 for all)
#smarti.analysis.conextSize=10

##Analysis Pipeline

## The analysis chain used to process conversations can be configured by the 
## following properties

## comma separated list of required analysis component (empty if none are
## required). If required components are missing the Analysis Service will
## not start
#smarti.analysis.required =

## comma separated list of optional analysis component.
##  - comma separated list of names to explicitly define the processors to be
##    used
##  - `*` to include all. If activated `!{name}` can be used to exclude
##    specific analysis components.
smarti.analysis.optional=*,!keyword.interestingterms.conversation


##Stanford NLP configuration

##NOTE: This takes only effect of the optional Redlink NLP processor for 
##      Stanford NLP is present.

## German Language configuration

##POS Tagger Model
#nlp.stanfordnlp.de.posModel={path}
##NER Model(s)
#nlp.stanfordnlp.de.nerModel={path}
##Parse Model
#Different parser options for German. This configurations do have a huge impact on
# heao requirements (see https://nlp.stanford.edu/software/parser-faq.shtml#k)
#uncomment all for the default edu/stanford/nlp/models/lexparser/germanFactored.ser.gz
nlp.stanfordnlp.de.parseModel=edu/stanford/nlp/models/lexparser/germanPCFG.ser.gz
#nlp.stanfordnlp.de.parseModel=edu/stanford/nlp/models/srparser/germanSR.ser.gz
#decreasing this reduces the memory footprint as it ignores long sentences for parsing
nlp.stanfordnlp.de.parseMaxlen=30
##Case Sensitive
## Indicates if the used model(s) are case sensitive (default=true). If enabled
## True Case annotation will be used to correct the case of the processed text
## before parsing it to Stanford NLP. If FALSE the text will be converted to
## lower case
#nlp.stanfordnlp.de.caseSensitive=true/false


##Interesting Term

## Interesting Terms is a kind of Keyword Extraction that uses `tf-idf` over
## a document corpus to detect the most relevant terms within a conversation.
## Implementation wise Solr is used to manage the text corpus and Solr MLT
## requests are used to retrieve relevant terms.

## Their are several ways to configure Solr endpoints to be used for
## interesting terms.

## The name suffix of the interesting term component
#keyword.solrmlt[0].name={name}

## The url of the solr core
#keyword.solrmlt[0].url=http://localhost:8983/solr/{core-name}

## The default field used in cases the lanugage is unknown or as fallback if no
## field is configured for the language of the conversation
#keyword.solrmlt[0].field = {gen-field}

## The field to be used for `{lang}` 
## (e.g. for German: `keyword.solrmlt[0].lang.de=text_de`)
#keyword.solrmlt[0].lang.{lang}={field}

## The above configuration requires a Solr Server. To allow the use of
## embedded Solr Servers specific modules are required. Currenty two of
## those exist.
## NOTE: The archives with the Solr cores are separate downloads.

## Absolute path to the archive with the German Wikipedia Corpus.
#solrcore.wikipedia.de.resource =

## Absolute path to the archive with the crawl of Systel related Webpages
#solrcore.crawl.systel.resource=


## Token Filter: Stopword

## This analysis components allows to reference stopword lists for extracted
## tokens. Its part of the `token-processor` module

## Stopword lists a text files with a single word per line. Empty lines and
## lines starting with `#` are ignored. Values are Spring resources 
## (e.g. file:/path, http(s)://, classpath:/path ..)

## List of stop words used for any language (in addition to language specific 
## stopwords). 
#processor.token.stopword.default =

## list of stop words for the language `lang`.
#processor.token.stopword.{lang} =


## Hasso Extraction

## Hasso was a spefic use case of the predecessor of Smarti. The module
## `hasso-vocabulary-extractor` provides two vocabulary based keyword extraction
## components. 

## `CSV` file with `;` as column separator and `utf-8` as encoding. One
## vocabulary entry per row. The value in the first column is the preferred
## label. Additional columns for synonyms. The content is expected to be in
## German language. Extracted Entities will have the type `term` and the tag
## `db-entity`.
#smarti.extractor.synonyms.db =

## `CSV` file with `,` as column separator and `utf-8` as encoding. One
## vocabulary entry per row. The value in the first column is the preferred
## label. Additional columns for synonyms. The content is expected to be in
## German language. Extracted Entities will have the type `term` and the tag
## `sap-entity`
#smarti.extractor.synonyms.sap = 


## - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

## Query Builder Default Configuration

## Query Builder are configured per Client via the Client Configuration service.
## However a system wide default configuration can be used to initialize 
## configurations for new clients.
## All following configuration properties are used to define this default
## configurations


## Solr Endpoint configuration

## A SolrEndpoint is used by the generic Solr `QueryProfider` provided by the
## `query-solr` module.

## The default state for new Solr Endpoint Configurations
#query.solr.enabled = true

## The URL of the Solr Endpoint (Solr Core)
#query.solr.solr-endpoint = http(s)://solr-host:port/solr/core-name

## Search Configuration

## Title search is disabled by default
#query.solr.search.title.enabled = false
##The name of the full text field are `null` or `empty` to use the default
## search field
#query.solr.search.title.field = 

## Full text search is enabled by default
#query.solr.search.full-text.enabled = true
## The name of the full text field are `null` to use the default field
#query.solr.search.full-text.field = 

## If related Document search enabled
#query.solr.search.related.enabled = false
## The fields to use for search for similar documents
#query.solr.search.related.fields

## Spatial (Geo) Search is enabled by default
#query.solr.search.spatial.enabled = true
## The name of the field used to search for location names or `null` to use
## the default field
#query.solr.search.spatial.locationNameField = 
## The name of the Solr field using a `latLonPointSpatial` type to search for
## documents near a extracted location (with included lat/lon information)
#query.solr.search.spatial.latLonPointSpatialField = 
## The name of the Solr field using a `rpt` type to search for documents near
## a extracted location (with included lat/lon information)
#query.solr.search.spatial.rptField = 
## The name of the Solr field using a `bbox` type to search for documents near
##  a extracted location (with included lat/lon information)
#query.solr.search.spatial.bboxField = 

##Temporal Search is disabled by default
#query.solr.search.temporal.enabled = false
## The name of the Solr field using the `DateRangeField` type used to search
## Documents near the extracted Date/Times or Date/Time ranges.
#query.solr.search.temporal.timeRangeField = 
## The name of the Solr date field used to search for Documents near extracted
## Date/Times or the start time of extracted ranges.
#query.solr.search.temporal.startTimeField = 
## The name of the Solr date field used to search for Documents near end date
## of extracted ranges.
#query.solr.search.temporal.endTimeField = 

##Result Mapping Configuration

## Those map fields in the Solr schema to fields known by the client. Needed to
## correctly present results in the UI
#query.solr.result.mappings.title =
#query.solr.result.mappings.description = 
#query.solr.result.mappings.link = 
#query.solr.result.mappings.type =
#query.solr.result.mappings.doctype = 
#query.solr.result.mappings.thumb = 
#query.solr.result.mappings.date = 
#query.solr.result.mappings.source = 

##Solr Defaults

## Under the prefix `query.solr.defaults` one can define defaults that are sent
## with every Solr request.

##Examples
#query.solr.defautls.rows = 10
#query.solr.defautls.df = text
